{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Data Science Methdology Final Assignment Overview",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Demonstrate your understanding of data science methodology.\n\nDuring this final project you'll complete 3 tasks for a total of 10 points to demonstrate your knowledge of CRISP-DM data methodology.\n\nFirst, you'll take on both the role of the client and the data scientist to develop a business problem related to one of the following topics:\n\n- Emails\n- Hospitals\n- Credit Cards\n  \nYou'll use the business problem you defined to demonstrate your knowledge of the Business Understanding stage.\n\nThen, taking on the role of a data scientist, you'll describe how you would apply data science methodology practices at each of the the listed stages to address the business problem you identified.\n\nYou'll enter your answers in the text fields provided online. After you submit your assignment, one of your peers who are is completing this assignment within the same session will grade your final project. You will also grade a peer's assignment.\n\nPlease note that this assignment is worth 10% of your final grade.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Requirements\n\n1. Take the role of client, develope a business problem in Emails/Hospitals/Credit Cards\n2. Describe how you would apply data science methodology practices at each of the the listed stages to address the business problem you identified\n3. My work will be graded by peers. I will also grade my peers in order to complete this assignment.",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Solution",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this assignment, I will implement **Cross Industry Process for Standard Data Mining (CRISP-DM)** on **Credit Fraud Detection** using **Decision Tree Model**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 1. Business Understanding",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Client - CTO from a leading digital banking group is interested to leverage technology to automate the fradulent detection process, particulat in real-time. \n\nA rising tech startup founder decideds to offer help by designing a decision tree model to automatically label a transaction as legitimate or fraudulent based on the card's historical purchasing behaviors.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 2. Analytic Approach",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A Decision Tree model is to be developed to analyze a training set comprising both fraudulent and legitimate credit card transactions. Variables indicating statistical deviations from a customer's credit card profile will be used to highlight inconsistencies when compared to the historical trends of the credit card.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 3. Data Req",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Variables related to the card profile will reveal patterns in card usage behavior. To assess in real-time if a transaction is fraudulent, the model must evaluate whether the transaction deviates from the cardholder's historical spending habits. Necessary historical data include geographical location, days of the month, hours of the day, and type of merchant, categorized by Merchant Category Code (MCC).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 4. Data Collection",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Request credit card profile and transaction data from the company's data database. The data will reflect the historiacl usage and therefore behavirol characteristics of the card. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 5. Data Understanding and Data Preparation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To identify potentially fraudulent transactions, we will consider significant deviations from established spending patterns. Since transactions at certain types of merchants can be more easily monetized and thus are more susceptible to fraud, we plan to categorize merchants based on the Merchant Category Code (MCC) according to their fraud risk potential. This categorization will reduce the number of individual MCC codes we need to examine. Consulting with experts in the field will aid in accurately grouping the MCCs.\n\nExperience with both digital and traditional banks shows that the data distribution between fraudulent and normal transactions is highly skewed, with normal transactions vastly outnumbering fraudulent ones. To address this imbalance, we will employ an undersampling strategy, reducing the number of normal transaction records in the training dataset to a manageable level. This approach will facilitate the model's ability to learn the characteristics of both normal and fraudulent transaction profiles.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6. Modeling and Evaluation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Our variables will include specific deviations from a profile's average statistics, such as regional statistics, daily transaction counts, and overall transaction statistics. To address the challenge of missing values, each node in the Decision Tree will identify the closest matching input fields to use as surrogates for the missing data. As mentioned earlier, employing an undersampling technique will help minimize the occurrence of False Negatives, where fraudulent transactions might otherwise be misclassified as normal.\n\nTo determine the most effective training set composition, we will experiment with ratios of fraudulent to normal transactions at 1:1, 1:3, and 1:7.\n\n                       | Training set | Test set |\n    ----------------------------------------------\n    1F to 1N Normal    | 750         |  535       | \n    1F to 1N Fraud     | 355         |  302       | \n    ----------------------------------------------\n    1F to 3N Normal    | 1295        | 1188       | \n    1F to 3N Fraud     | 355         |  302       | \n    ----------------------------------------------\n    1F to 7N Normal    | 2652        |  2296      | \n    1F to 7N Fraud     | 355         |  302       | \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For the Decision Tree model, 70% of both normal and fraudulent transactions will constitute the training set, while the remaining 30% will serve as the test set for evaluating the model's performance. Within each sample, the count of fraudulent transactions remains constant due to their limited number, whereas the quantity of normal transactions varies in line with the previously mentioned ratios (1:1, 1:4, and 1:9).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}